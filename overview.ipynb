{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog here: https://wordpress.com/post/brianfarish3.wordpress.com/168\n",
    "\n",
    "We are here: https://docs.aws.amazon.com/textract/latest/dg/api-async.html\n",
    "\n",
    "Diagram of this pipeline: https://app.diagrams.net/#Hcodeslp%2Faws_arch_diagrams%2Fmaster%2Ftextract-stepfns.drawio\n",
    "\n",
    "AWS has this which could be helpful to me in writing my code in the testract JSON to RDS Lambda.\n",
    "\n",
    "boto3 textract documentation: \n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html#textract\n",
    "\n",
    "AWS recommends using an asynchronous function to process multiple page files. I'm going to use step functions. More details on that decision in the blog."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IAM\n",
    "The role will be named: step-functions-lambda-role. The tag is \"app\": \"document-parser\"\n",
    "I am creating an IAM role for the Lambda function that will allow Step Functions to access resources. The policy will be called \"AllowStepFunctionStateMachineStart\". It uses the AWS standard policy AWSLambdaRole, which generates cloudwatch logs. Also I am adding permission to start state machines with this policy: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"states:StartExecution\",\n",
    "            \"Resource\": \"arn:aws:states:us-east-1:415832459288:stateMachine:Doc-Parser-Pipeline\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP FUNCTION\n",
    "I'm creating a step function called Doc-Parser-Pipeline and attaching the above role to it. I'm not turning on logs now, but may later, as I inevitably mess up. Maybe even tracing to with X-ray. Tagged with app:document-parser.\n",
    "\n",
    "State machine arn:  arn:aws:states:us-east-1:415832459288:stateMachine:Doc-Parser-Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LAMBDA\n",
    "I'm creating a step function \"run-step-function-lambda\" tagged with app:document-parser.\n",
    "\n",
    "Adding environment variable:\n",
    "STATEMACHINEARN:arn:aws:states:us-east-1:415832459288:stateMachine:Doc-Parser-Pipeline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#S3\n",
    "Creating document upload bucket. Not public. Tag app:document-parser\n",
    "Bucket name: \n",
    "doc-upload-bucket-doc-parser-app\n",
    "S3 BUCKET ARN:\n",
    "arn:aws:s3:::doc-upload-bucket-doc-parser-app\n",
    "\n",
    "Properties > event notifications > create\n",
    "Event name: \n",
    "trigger-document-parsing-event \n",
    "\n",
    "Suffix:\n",
    ".pdf\n",
    "\n",
    "Object creation, checking \"all object create events\". From the Lambda dropdown at the bottom selecting \"run-step-functions-lambda\"\n",
    "\n",
    "Creating an S3 bucket for textract's JSON object output objects used during the pipeline. No triggers on it for now.\n",
    "\n",
    "Name: \n",
    "textract-json-output-parser-app\n",
    "\n",
    "ARN:\n",
    "arn:aws:s3:::textract-json-output-parser-app\n",
    "\n",
    "We need a bocket policy on this last bucket: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Id\": \"Policy1683945477760\",\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "      {\n",
    "        \"Sid\": \"Stmt1683945475477\",\n",
    "        \"Action\": \"s3:PutObject\",\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Resource\": \"arn:aws:s3:::textract-json-output-parser-app/*\",\n",
    "        \"Principal\": {\n",
    "          \"AWS\": [\n",
    "            \"arn:aws:iam::415832459288:role/service-role/doc-to-json-textract-role-7n40j7gg\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LAMBDA\n",
    "\n",
    "We are going to create three Lambdas ***BUT*** they will not actually have the logic we need in them yet. They are basically placeholders. These are in order that they are invoked in the step function:\n",
    "\n",
    "Name:\n",
    "doc-to-json-textract\n",
    "ARN:\n",
    "arn:aws:lambda:us-east-1:415832459288:function:doc-to-json-textract\n",
    "\n",
    "Name:\n",
    "textract-status-checker\n",
    "ARN:\n",
    "arn:aws:lambda:us-east-1:415832459288:function:textract-status-checker\n",
    "\n",
    "Name:\n",
    "parse-textract-json-obj-for-rds\n",
    "ARN:\n",
    "arn:aws:lambda:us-east-1:415832459288:function:parse-textract-json-obj-for-rds\n",
    "\n",
    "#Reminder: At this point, all of these (and the initial run-step-functions-lambda also) are placeholders and contain no real logic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STEP FUNCTIONS\n",
    "\n",
    "JSON will be pasted after this block.\n",
    "\n",
    "Editing - Deleting the default Hello and World states from the \"States\" key. \n",
    "Generate code snippet > Invoke a function\n",
    "Select fn from dropdown > doc-to-json-textract.\n",
    "\n",
    "Click copy to copy the invoke JSON and paste into definition code snippet after \"States\": {. Click format JSON to clean it up.\n",
    "Rename \"Invoke function\" to \"Start extraction\".  Make sure key above is \"StartAt\": \"Start Extraction\"\n",
    "\n",
    "Change Next key to \"Next:\" \"Wait for textract\"\n",
    "\n",
    "Add in Wait State. Change name to \"Wait for Textract\"\n",
    "\n",
    "Generate code snippet > Invoke a function\n",
    "Select fn from dropdown > textract-status-checker.  Change first line of new add from Invoke function to \"Check textract status\".  Make sure above key in Wait state is \"Next\": \"Check textract status\".\n",
    "\n",
    "Add a code snippet for a Choice state. Will be edited heavily see code below. Don't need a \"NOT\" block. (The default state later will go back to the Wait state.) Essentially two blocks with \"StringEquals\": \"COMPLETED\" or second with \"StringEquals\": \"FAILED\". The variable \"$.Payload.TextractJobStatus\".\n",
    "\n",
    "Change kv Default to \"Default\": \"Wait for textract\"\n",
    "\n",
    "Generate code snippet > Invoke a function\n",
    "Select fn from dropdown > parse-textract-json-obj-for-rds.  Change first line of new add from Invoke function to \"Parse textract JSON\".  Make sure above key in Wait state is \"Next\": \"Parse textract JSON\".\n",
    "\n",
    "In choices COMPLETED block set kv \"Next\": \"Parse textract JSON\".\n",
    "\n",
    "Change last \"Next\" to kv \"End\": true\n",
    "\n",
    "For FAILED Choice block:\n",
    "Generate snippet > flow control state > Fail state. Copy. Paste after END. Change as you see. Set FAILED block kv \"Next\": \"Textract failed\"\n",
    "\n",
    "Chart here: \n",
    "/Users/bfaris96/Desktop/data_engineer/FCC-doc-tables/school_assessments_proj/Screen Shot 2023-05-08 at 3.59.30 PM.png\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First pass at \"run-step-function-lambda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    step_function_client = boto3.client('stepfunctions')\n",
    "    state_machine_arn = os.environ['STATEMACHINEARN']\n",
    "    \n",
    "    # Extract relevant information from the S3 event\n",
    "    s3_bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    s3_object_key = event['Records'][0]['s3']['object']['key']\n",
    "    \n",
    "    # Prepare the input for the state machine\n",
    "    step_state = {\n",
    "        \"s3Bucket\": s3_bucket,\n",
    "        \"s3ObjectKey\": s3_object_key\n",
    "    }\n",
    "    \n",
    "    # Start the execution of the state machine\n",
    "    response = step_function_client.start_execution(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        input=json.dumps(step_state)\n",
    "    )\n",
    "\n",
    "    return json.dumps(response, default=str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First pass at \"doc-to-json-textract\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    textract_client = boto3.client('textract')\n",
    "\n",
    "    # Retrieve input from the state machine\n",
    "    step_state = event['Input']\n",
    "    s3_bucket = step_state['s3Bucket']   # this is the initial upload bucket\n",
    "    s3_object_key = step_state['s3ObjectKey']   # this is the initial upload object\n",
    "\n",
    "    # Prepare the output bucket\n",
    "    output_bucket = \"textract-json-output-parser-app\"\n",
    "\n",
    "    # Start the Textract job for the uploaded document using StartDocumentTextDetection API for extracting raw text\n",
    "    start_document_text_detection_response = textract_client.start_document_text_detection(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3_bucket,\n",
    "                'Name': s3_object_key\n",
    "            }\n",
    "        },\n",
    "        OutputConfig={\n",
    "            'S3Bucket': output_bucket,\n",
    "            'S3Prefix': f\"{s3_object_key}-text-detection/\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Start the Textract job for the uploaded document using StartDocumentAnalysis API for extracting tables\n",
    "    start_document_analysis_response = textract_client.start_document_analysis(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3_bucket,\n",
    "                'Name': s3_object_key\n",
    "            }\n",
    "        },\n",
    "        FeatureTypes=['TABLES'],\n",
    "        OutputConfig={\n",
    "            'S3Bucket': output_bucket,\n",
    "            'S3Prefix': f\"{s3_object_key}-table-analysis/\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Creating keys for the text detection and table analysis output objects\n",
    "    text_detection_output_prefix = f\"{s3_object_key}-text-detection/\"\n",
    "    table_analysis_output_prefix = f\"{s3_object_key}-table-analysis/\"\n",
    "    step_state['textDetectionOutputObjectKey'] = f\"{text_detection_output_prefix}{s3_object_key}.json\"\n",
    "    step_state['tableAnalysisOutputObjectKey'] = f\"{table_analysis_output_prefix}{s3_object_key}.json\"\n",
    "\n",
    "    # Update the step-state with the Textract JobIds\n",
    "    step_state['textDetectionJobId'] = start_document_text_detection_response['JobId']\n",
    "    step_state['tableAnalysisJobId'] = start_document_analysis_response['JobId']\n",
    "\n",
    "    return step_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First pass at \"textract-status-checker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    textract_client = boto3.client('textract')\n",
    "\n",
    "    # Retrieve the Textract JobIds, S3 bucket, and object key from the input event\n",
    "    step_state = event['Input']['Payload']\n",
    "    text_detection_job_id = step_state['textDetectionJobId']\n",
    "    table_analysis_job_id = step_state['tableAnalysisJobId']\n",
    "\n",
    "    # Check the status of the raw text extraction job\n",
    "    text_detection_status_response = textract_client.get_document_text_detection(JobId=text_detection_job_id)\n",
    "    text_detection_status = text_detection_status_response['JobStatus']\n",
    "\n",
    "    # Check the status of the table extraction job\n",
    "    table_analysis_status_response = textract_client.get_document_analysis(JobId=table_analysis_job_id)\n",
    "    table_analysis_status = table_analysis_status_response['JobStatus']\n",
    "\n",
    "    # Add detection and analysis status to the step state\n",
    "    step_state['textDetectionStatus'] = text_detection_status\n",
    "    step_state['tableAnalysisStatus'] = table_analysis_status\n",
    "\n",
    "    # Add TextractJobStatus key to the step state based on the status of both jobs\n",
    "    if text_detection_status == 'SUCCEEDED' and table_analysis_status == 'SUCCEEDED':\n",
    "        step_state['TextractJobStatus'] = 'COMPLETED'\n",
    "    elif text_detection_status == 'FAILED' or table_analysis_status == 'FAILED':\n",
    "        step_state['TextractJobStatus'] = 'FAILED'\n",
    "\n",
    "    # Return the status of both Textract jobs along with the S3 bucket and object key\n",
    "    return step_state\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IAM\n",
    "More IAM roles and policies: \n",
    "\n",
    "For the role attached to doc-to-json-textract:\n",
    "Policy name: StartTextractTextDetectAndAnalysisAndGetPutS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"textract:StartDocumentTextDetection\",\n",
    "                \"textract:StartDocumentAnalysis\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::doc-upload-bucket-doc-parser-app/*\",\n",
    "                \"arn:aws:s3:::textract-json-output-parser-app/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the role attached to textract-status-checker:\n",
    "Name: GetTextractTextDetectAndAnalysisObjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"textract:GetDocumentTextDetection\",\n",
    "                \"textract:GetDocumentAnalysis\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need this policy on status-checker too: \n",
    "Policy name: S3GetPutListGetLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:GetBucketLocation\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::doc-upload-bucket-doc-parser-app\",\n",
    "                \"arn:aws:s3:::doc-upload-bucket-doc-parser-app/*\",\n",
    "                \"arn:aws:s3:::textract-json-output-parser-app\",\n",
    "                \"arn:aws:s3:::textract-json-output-parser-app/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before this can be written we have to create the database that it will be put into, otherwise I will have no idea how to parse this. It will also need an IAM role and policy attached to it.\n",
    "\n",
    "Take  look at this: https://github.com/aws-samples/amazon-textract-response-parser\n",
    "\n",
    "First pass at parse-textract-json-obj-for-rds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-05-12: we have lift off! we got a JSON object back and now we just have to parse it. See 1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'school_assessments_proj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/bfaris96/Desktop/data_engineer/FCC-doc-tables/school_assessments_proj/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# the python will go here it is being developed in the other py files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school_assessments_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
